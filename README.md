# Variant Prioritization Benchmark

## Introduction
The history of the development of machine learning systems has long been guided by the datasets and benchmarks available to researchers. This spans classic datasets such as ImageNet, which encouraged tremendous improvement in object recognition tasks, and the Stanford Question Answering Dataset (SQuAD), which played a similar role in natural language processing, as well as scientific data repositories like the Protein Data Bank without which the AlphaFold breakthrough would not have been possible. Recent work has established Multiplexed Assays of Variant Effects (MAVEs) in a similar role for tools dedicated to predicting the effects of protein variants. MAVEs provide an experimental measure of the functional impact of a variant (typically an amino acid substitution) and have become popular due in part to their ability to be freely downloaded and redistributed through efforts such as the ProteinGym. However, functional effects are not necessarily pathogenic effects. 

One of the most common uses of variant effect prediction tools (AlphaMissense, PrimateAI-3D, EVE, CADD, etc) is to identify pathogenic variants in the context of cancer or rare disease. We have observed a poor correlation between the performance of tools at predicting functional variant effects in MAVE datasets and prioritizing disease-causing variants in individuals with rare diseses. Therefore, we believe the field needs an open and freely-redistributable benchmark for medical genetics in order to encourage and measure improvement in that domain, which we view as a complement to MAVEs. The challenge with this is that individual-level human genetic variation data is typically kept under restricted access in order to protect the privacy of those individuals. Most exceptions to this, such as individuals in the 1000 Genomes Project, have been widely used in public allele frequency databases and as a result have far fewer ultra-rare variants than a typical human (and no variants with allele frequency of 0). Since many tools utilize allele frequency in making variant pathogenicity predictions, use of such samples would not replicate real-world use scenarios. 

Here, we release a benchmark that we hope will be used analogously to MAVEs for the medical genetics task of identifying rare disease-causing pathogenic variants in individuals. We have collected tens of thousands of rare disease-causing variants from ClinVar with known modes of inheritance and combine them with over 100 individuals from the Personal Genome Project who have consented to open access and free distribution of their individual genotype data, but who are not present in any major public allele frequency databases (to the best knowledge of the authors). 

## Methods
Pathogenic variants were collected from ClinVar using its archive of variant summary files. The January variant summary files were collected for the years 2017, 2018, 2019, 2020, 2021, 2022, and 2023 as well as the October 2023 file (which was the most recent file at the time). Additional years are planned to be added as time passes. For each year, we selected the pathogenic or likely pathogenic missense variants that had been added in that year which had a one-star or greater level of support and which also were associated with an OMIM phenotype. We applied data from OMIM to separate these variants into those with dominant and recessive modes of action. This enabled the creation of time-resolved datasets with hundreds to thousands of variants being used for evaluation in each year. The purpose in creating time-resolved datasets is to allow users to ignore results for tools on particular years if they were trained in a supervised learning paradigm with data that included variants from that year of ClinVar data. 

The 108 individuals from the Personal Genome Project were selected randomly from among those in the project who have whole genome sequencing data available. The samples are overwhelmingly of European ancestry, a weakness of the initial version of this benchmark which we hope to remedy in the future. All 108 genomes were sequenced by Complete Genomics and the processed variant calls were downloaded from the [Personal Genome Project website](https://my.pgp-hms.org/public_genetic_data). 

Variant prediction scores for each test variant and each missense variant in each of the 108 individuals were downloaded either from dbNSFP4.4a or by downloading the pre-computed predictions of the individual tools. All tool scores were normalized to a range of 0 to 1 with values closer to 1 representing greater likelihood of pathogenicity. In cases where a tool emitted multiple scores for the same mutation (for example, if the mutation affected multiple variants), the highest (most deleterious) prediction value was used. A total of 52 tools have been collected and benchmarked so far. The scores for 46 tools were collected from dbNSFP4.4a, while scores for Maverick, MAPPIN, AlphaMissense, EVE, PrimateAI-3D, and ESM1b were collected separately. 

For each tool, its performance for each year of ClinVar data was derived as follows. Each pathogenic variant was individually 'spiked into' the set of variants for each individual. Next, the tool would score each missense variant in that individual (including the pathogenic one). Then, variants would be ranked in descending order by the tool's score. The rank of the causal variant within the set would be taken as the raw measure of performance of the tool for that variant in that individual. This rank value was then normalized by dividing it by the total number of variants in that individual for which this tool provided scores. In this way, the normalized score gives a sort of 'rank percentile' for the variant which normalizes out any advantage a tool might get if it only has scores available for a subset of all missense variants. This 'spike-in' process is then repeated for each of the 31,811 pathogenic variants being placed into each of the 108 individuals for a total of over 3.4 million tests per tool. These normalized rank values are then plotted to show the cumulative number of simulated cases that would have been solved within the top, say, 0.01% to 0.3% of variants within an individual. This method of evaluation is meant to show how good of a job the tool is doing at 'picking the needle out of the haystack'. Finally, we take the area under this cumulative cases solved curve in order to provide a final score for each tool. A perfect tool would get an area under the curve score of 1, meaning that it gives top rank to the causal variant every single time. While a poor tool would get a score of 0, meaning that it takes it longer to find any of the causal variants than the window of evaluation here (typically, the tool did not prioritize the causal variant into the top 1% of variants in the individual). 

## Results
## Discussion
## Data Access
## References
